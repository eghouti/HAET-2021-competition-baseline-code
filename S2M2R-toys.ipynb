{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook pour S2M2R\n",
    "\n",
    "### Quelques éléments de rappel\n",
    "\n",
    "La méthode S2M2R permet d'entraîner un backbone de façon efficace. Pour cela elle combine plusieurs ingrédients : self-supervision avec des rotations et manifold-mixup.\n",
    "\n",
    "Dans le cadre de ce notebook, nous allons tenter de mettre à l'épreuve cette méthode sur le jeu de donnée CIFAR-FS, plus petit que miniImageNet, mais permettant d'entraîner plus vite.\n",
    "\n",
    "Nous allons nous concentrer sur une architecture de type ResNet, car elles sont connues pour leur bonne capacité à généraliser.\n",
    "\n",
    "### Importation des données\n",
    "\n",
    "Tout d'abord il nous faut charger quelques bibliothèques utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "from torchvision import datasets, transforms\n",
    "print(np.__version__)\n",
    "print(torch.__version__)\n",
    "\n",
    "save_path = \"/home/tesbed/datasets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite il nous faut définir les \"splits\", c'est-à-dire quelles classes correspondent au base dataset, au val dataset et au novel dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_labels = [\"baby\",\"bed\",\"bicycle\",\"chimpanzee\",\"fox\",\"leopard\",\"man\",\"pickup_truck\",\"plain\",\"poppy\",\"rocket\",\"rose\",\"snail\",\"sweet_pepper\",\"table\",\"telephone\",\"wardrobe\",\"whale\",\"woman\",\"worm\"]\n",
    "val_labels = [\"otter\",\"motorcycle\",\"television\",\"lamp\",\"crocodile\",\"shark\",\"butterfly\",\"beaver\",\"beetle\",\"tractor\",\"flatfish\",\"maple_tree\",\"camel\",\"crab\",\"sea\",\"cattle\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons à présent charger les données, et identifier les trois datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/tesbed/datasets\"\n",
    "\n",
    "data_train = datasets.CIFAR100(path, train=True, download=True)\n",
    "data_val = datasets.CIFAR100(path, train=False, download=True)\n",
    "\n",
    "all_data = np.concatenate((data_train.data, data_val.data))\n",
    "all_labels = np.concatenate((data_train.targets, data_val.targets))\n",
    "\n",
    "novel_targets = [data_train.class_to_idx[label] for label in novel_labels]    \n",
    "val_targets = [data_train.class_to_idx[label] for label in val_labels]\n",
    "train_targets = [x for x in np.arange(100) if x not in novel_targets and x not in val_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60\n",
    "\n",
    "from torchvision.datasets import VisionDataset\n",
    "from typing import Any, Callable, Optional, Tuple\n",
    "from PIL import Image\n",
    "class CIFAR(VisionDataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root : str,\n",
    "            transform: Optional[Callable] = None,\n",
    "            target_transform: Optional[Callable] = None\n",
    "    ) -> None:\n",
    "\n",
    "        super(CIFAR, self).__init__(root, transform=transform, target_transform=target_transform)\n",
    "        \n",
    "        self.data = all_data\n",
    "        self.targets = all_labels\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.data.shape[0]\n",
    "\n",
    "train_transforms = [        \n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip()\n",
    "    ] # used for standard data augmentation during training\n",
    "\n",
    "standard_transforms = [\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ] # used for all data\n",
    "\n",
    "transform_train = transforms.Compose(train_transforms + standard_transforms)\n",
    "transform_all = transforms.Compose(standard_transforms)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(CIFAR(path, transform=transform_train), np.nonzero(np.isin(all_labels,train_targets))[0]),\n",
    "    batch_size=batch_size, shuffle=True, num_workers = 4)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(CIFAR(path, transform=transform_all), np.nonzero(np.isin(all_labels,val_targets))[0]),\n",
    "    batch_size=batch_size, shuffle=False, num_workers = 4)\n",
    "novel_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(CIFAR(path, transform=transform_all), np.nonzero(np.isin(all_labels,novel_targets))[0]),\n",
    "    batch_size=batch_size, shuffle=False, num_workers = 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut vérifier la quantité de données dans chaque dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38400\n",
      "9600\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "print(batch_size * len(train_loader))\n",
    "print(batch_size * len(val_loader))\n",
    "print(batch_size * len(novel_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition des architectures\n",
    "\n",
    "Il est à présent temps de construire un réseau de neurones pour notre backbone. Il faut non seulement bien définir sa structure mais s'assurer qu'on peut récupérer l'avant dernière couche facilement. On va ici considérer un resnet18 ou un resnet20 avec un multiplicateur pour le nombre de feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un resnet est obtenu par assemblage de blocks, ici on considère des resnet très simples où on utilise uniquement des basicblocks\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        return out\n",
    "        \n",
    "class BasicBlockWRN(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride, drop_rate):\n",
    "        super(BasicBlockWRN, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.droprate = drop_rate\n",
    "        self.equalInOut = (in_planes == out_planes)\n",
    "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
    "                               padding=0, bias=False) or None\n",
    "    def forward(self, x):\n",
    "        if not self.equalInOut:\n",
    "            x = self.relu1(self.bn1(x))\n",
    "        else:\n",
    "            out = self.relu1(self.bn1(x))\n",
    "        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
    "        if self.droprate > 0:\n",
    "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
    "        out = self.conv2(out)\n",
    "        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n",
    "\n",
    "class NetworkBlock(nn.Module):\n",
    "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, drop_rate):\n",
    "        super(NetworkBlock, self).__init__()\n",
    "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, drop_rate)\n",
    "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, drop_rate):\n",
    "        layers = []\n",
    "        for i in range(int(nb_layers)):\n",
    "            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, drop_rate))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour pouvoir implémenter manifold-mixup, il faut modifier le calcul dans le réseau. On va commencer par introduire les fonctions d'interpolation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0, lam = None, use_cuda=True):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if lam == None:\n",
    "        if alpha > 0:\n",
    "            lam = np.random.beta(alpha, alpha)\n",
    "        else:\n",
    "            lam = 1    \n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mix_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dorénavant on peut définir notre réseau :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on peut à présent définir notre resnet\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, feature_maps, num_classes=100):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = feature_maps\n",
    "        self.length = len(num_blocks)\n",
    "        self.conv1 = nn.Conv2d(3, feature_maps, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(feature_maps)\n",
    "        layers = []\n",
    "        layers.append(self._make_layer(block, feature_maps, num_blocks[0], stride=1))\n",
    "        layers.append(self._make_layer(block, 2*feature_maps, num_blocks[1], stride=2))\n",
    "        layers.append(self._make_layer(block, 4*feature_maps, num_blocks[2], stride=2))\n",
    "        layers.append(self._make_layer(block, 8*feature_maps, num_blocks[3], stride=2))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.linear = nn.Linear(8*feature_maps*block.expansion, num_classes, bias=False)\n",
    "        self.rotationLinear = nn.Linear(8*feature_maps*block.expansion, 4, bias=False)\n",
    "        \n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for i in range(len(strides)):\n",
    "            stride = strides[i]\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, mixup_target = None):\n",
    "        if mixup_target is not None:\n",
    "            mixup_layer = random.randint(0, len(self.layers))\n",
    "        else:\n",
    "            mixup_layer, target_a, target_b, lam = -1, None, None, None\n",
    "        out = x\n",
    "        if mixup_layer == 0:\n",
    "            out, target_a, target_b, lam = mixup_data(out, mixup_target, lam = 0.4)\n",
    "        out = F.relu(self.bn1(self.conv1(out)))\n",
    "        for i in range(len(self.layers)):\n",
    "            out = self.layers[i](out)\n",
    "            if mixup_layer == i + 1:\n",
    "                out, target_a, target_b, lam = mixup_data(out, mixup_target, lam = 0.4)\n",
    "            out = F.relu(out)\n",
    "        out = F.avg_pool2d(out, out.shape[2])\n",
    "        features = out.view(out.size(0), -1)\n",
    "        out = self.linear(features)\n",
    "        out_rotation = self.rotationLinear(features)\n",
    "        return out, out_rotation, features, target_a, target_b, lam\n",
    "    \n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, feature_maps, depth = 28, widen_factor = 10, num_classes = 100, drop_rate = 0.5):\n",
    "        super(WideResNet, self).__init__()\n",
    "        nChannels = [feature_maps, feature_maps*widen_factor, 2 * feature_maps*widen_factor, 4 * feature_maps*widen_factor]\n",
    "        n = (depth - 4) / 6\n",
    "        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        self.blocks = torch.nn.ModuleList()\n",
    "        self.blocks.append(NetworkBlock(n, nChannels[0], nChannels[1], BasicBlockWRN, 1, drop_rate))\n",
    "        self.blocks.append(NetworkBlock(n, nChannels[1], nChannels[2], BasicBlockWRN, 2, drop_rate))\n",
    "        self.blocks.append(NetworkBlock(n, nChannels[2], nChannels[3], BasicBlockWRN, 2, drop_rate))\n",
    "        self.bn = nn.BatchNorm2d(nChannels[3])\n",
    "        self.linear = nn.Linear(nChannels[3], int(num_classes))\n",
    "        self.rotationLinear = nn.Linear(nChannels[3], 4, bias=False)\n",
    "\n",
    "    def forward(self, x, type_features = \"post\", mixup_target= None, lam = None):\n",
    "        if mixup_target is not None:\n",
    "            mixup_layer = random.randint(0,3)\n",
    "        else:\n",
    "            mixup_layer, target_a, target_b, lam = -1, None, None, None\n",
    "\n",
    "        out = x\n",
    "        if mixup_layer == 0:\n",
    "            out, target_a, target_b, lam = mixup_data(out, mixup_target, lam=lam)\n",
    "        \n",
    "        out = self.conv1(out)\n",
    "        for i in range(len(self.blocks)):\n",
    "            out = self.blocks[i](out)\n",
    "            if mixup_layer == i + 1:\n",
    "                out, target_a, target_b, lam = mixup_data(out, mixup_target, lam=lam)\n",
    "        if type_features == \"pre\":\n",
    "            features = out\n",
    "        out = torch.relu(self.bn(out))\n",
    "        if type_features == \"all\":\n",
    "            features = out\n",
    "        out = F.avg_pool2d(out, out.size()[2:])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        if type_features == \"post\":\n",
    "            features = out\n",
    "        out = self.linear(features)\n",
    "        out_rotation = self.rotationLinear(features)\n",
    "        return out, out_rotation, features, target_a, target_b, lam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit à présent un resnet particulier en choisissant le nombre de blocks et leur composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet20(feature_maps):\n",
    "    return ResNet(BasicBlock, [3,3,3], feature_maps)\n",
    "\n",
    "def ResNet18(feature_maps):\n",
    "    return ResNet(BasicBlock, [2,2,2,2], feature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are running on cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"We are running on \" + str(device))\n",
    "\n",
    "def generate_model(feature_maps, model_type):\n",
    "    model = model_type(feature_maps)\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### entraînement du modèle\n",
    "\n",
    "Il est à présent temps d'entraîner notre modèle. Attention cela peut être très long !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut à présent écrire la fonction d'entraînement pour une époque :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# les arguments sont : le modèle, le device utilisé, le dataset d'entraînement, l'optimiseur utilisé, puis un paramètre permettant de décider d'utiliser ou non manifold-mixup, et un paramètre de force de la loss de classification par rotation\n",
    "def train(model, device, train_loader, optimizer, classification = True, mm = False, rotations = True):\n",
    "    model.train() # on prévient le modèle de passer en mode \"train\", ce qui est important notamment pour les BatchNorm\n",
    "    accuracy = 0 # utilisé pour l'affichage\n",
    "    total_loss = 0 # idem\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        if mm:\n",
    "            output, _, _, target_a, target_b, lam = model(data, mixup_target = target)\n",
    "            loss = mix_criterion(torch.nn.CrossEntropyLoss(), output, target_a, target_b, lam)\n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        if rotations:\n",
    "            x0 = data\n",
    "            x1 = x0.transpose(3,2).flip(2)\n",
    "            x2 = x1.transpose(3,2).flip(2)\n",
    "            x3 = x2.transpose(3,2).flip(2)\n",
    "            split = data.shape[0] // 4\n",
    "            x0, x1, x2, x3 = x0[:split], x1[split:2*split], x2[2*split:3*split], x3[3*split:]\n",
    "        \n",
    "            target_rotation = torch.tensor([0]*x0.shape[0] + [1]*x1.shape[0] + [2]*x2.shape[0] + [3]*x3.shape[0]).to(device)        \n",
    "            data_rot = torch.cat([x0, x1, x2, x3], dim = 0)\n",
    "            output, output_rotation, _, _, _, _ = model(data_rot)\n",
    "            loss = torch.nn.CrossEntropyLoss()(output_rotation, target_rotation)\n",
    "            loss.backward()          \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        if classification:\n",
    "            output, output_rotation, features, _, _, _ = model(data)\n",
    "            loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "    return total_loss / (1+batch_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis la méthodologie complète pour entraîner un réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_tick = time.time()\n",
    "def train_model(model, epochs, lr, validate, val_loader, novel_loader, type_features = \"post\", classification = False, mm = True, rotations = True, validate_each_epoch = True):\n",
    "    if lr > 0:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = lr, momentum = 0.9, weight_decay = 5e-4)\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "    best_score_val = 0\n",
    "    for epoch in range(epochs):        \n",
    "        loss = train(model, device, train_loader, optimizer, classification = classification, mm = mm, rotations = rotations)        \n",
    "        print(\"\\rEpoch: {:4d}, loss: {:.5f}\".format(epoch, loss), end=\"\")\n",
    "        if validate_each_epoch:\n",
    "            m, _ = validate(model, val_loader, type_features = type_features)\n",
    "            print(\" val score: {:.5f}\".format(m), end=\"\")\n",
    "            if m > best_score_val:\n",
    "                n, features = validate(model, novel_loader, type_features = type_features)\n",
    "                print(\" novel score: {:.5f}\".format(n), end = \"\")\n",
    "        new_time = time.time()\n",
    "        spent_time = int(new_time - start_tick)\n",
    "        print(\" {:d}h{:02d}m{:02d}\".format(spent_time // 3600, (spent_time % 3600) // 60, spent_time % 60), end =\"\")\n",
    "    print()\n",
    "    if not validate_each_epoch:\n",
    "        n, features = validate(model, novel_loader, type_features = type_features)\n",
    "    torch.save(features, save_path + datetime.datetime.now().strftime(\"%Y-%M-%d-%H-%M\") + \"_novel.pt\")\n",
    "    print(\"\\nFinal score is: \" + str(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation et choix des hyperparamètres\n",
    "\n",
    "Théoriquement, il est possible de choisir les hyperparamètres du modèle en utilisant le val_dataset. Pour ce faire, il faut déterminer une mesure de qualité. Comme on a déjà programmé simpleshot, on va l'utiliser pour obtenir un score de généralisation.\n",
    "\n",
    "Dans un premier temps on va récupérer toutes les données de validation passée au travers du backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_per_class = 600 # nombre d'éléments par classe avec cifar-FS\n",
    "\n",
    "def features_of_dataset(model, loader, type_features):\n",
    "    model.eval()\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    for i, (data, target) in enumerate(loader):\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            _, _, features, _, _, _ = model(data, type_features = type_features)\n",
    "        all_features += [features.cpu()]\n",
    "        all_labels += target    \n",
    "    all_features = torch.cat(all_features, dim = 0)\n",
    "    all_labels = torch.stack(all_labels, 0)\n",
    "\n",
    "    data = torch.zeros((0, elements_per_class, all_features.shape[1]))\n",
    "    labels = all_labels.clone()\n",
    "    while labels.shape[0] > 0:\n",
    "        indices = torch.where(all_labels == labels[0])[0]\n",
    "        data = torch.cat([data, all_features[indices,:].view(1, elements_per_class, -1)], dim = 0)\n",
    "        indices = torch.where(labels != labels[0])[0]\n",
    "        labels = labels[indices]\n",
    "    model = model.to(device)\n",
    "    return data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À présent, on peut calculer un score à l'aide de l'algorithme simpleshot :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_indices = np.arange(elements_per_class)\n",
    "def shuffle(data):\n",
    "    global shuffle_indices    \n",
    "    for i in range(data.shape[0]):\n",
    "        shuffle_indices = np.random.permutation(shuffle_indices)\n",
    "        data[i,:,:] = data[i,shuffle_indices,:]\n",
    "        \n",
    "# on peut à présent générer un run simplement\n",
    "def generate_run(w, k, q, data):\n",
    "    shuffle(data)\n",
    "    classes = np.random.permutation(np.arange(data.shape[0]))[:w]\n",
    "    dataset = data[classes,:k+q,:]\n",
    "    return dataset\n",
    "\n",
    "def stats(precisions):\n",
    "    return np.mean(precisions), (np.std(precisions) * 1.96 / math.sqrt(len(precisions)))\n",
    "\n",
    "def center(dataset, data):\n",
    "    mean = torch.mean(data.view(-1,data.shape[-1]), dim=0)\n",
    "    return dataset - mean.view(1, 1, -1)\n",
    "\n",
    "def normalize(dataset):\n",
    "    return dataset / torch.norm(dataset, p = 2, dim = 2, keepdim = True)\n",
    "\n",
    "def ncm(dataset, k):\n",
    "    means = dataset[:,:k,:].mean(dim=1)\n",
    "    res = []\n",
    "    for i in range(dataset.shape[0]):\n",
    "        dist = torch.norm(dataset[i,k:,:] - means.view(means.shape[0], 1, means.shape[1]), dim = 2, p = 2)\n",
    "        _, decisions = torch.min(dist, dim = 0)\n",
    "        res.append((decisions == i).float().mean())\n",
    "    return np.mean(res)\n",
    "\n",
    "def simpleshot(dataset, data, k, no_feature_transforms = False):\n",
    "    if not(no_feature_transforms):\n",
    "        dataset = center(dataset, data)\n",
    "        dataset = normalize(dataset)\n",
    "    return ncm(dataset, k)\n",
    "\n",
    "def perfs(w, k, q, runs, data, no_feature_transforms = False):\n",
    "    precisions = []\n",
    "    precisions_lr = []\n",
    "    for i in range(runs):\n",
    "        dataset = generate_run(w, k, q, data)\n",
    "        precisions.append(simpleshot(dataset, data, k, no_feature_transforms = no_feature_transforms))\n",
    "    mean, _ = stats(precisions)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut assembler tout ça dans une fonction de validation très simple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, type_features = \"post\", runs = 1000):\n",
    "    data = features_of_dataset(model, loader, type_features)\n",
    "    return(perfs(5, 5, 15, runs, data)), data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expériences\n",
    "\n",
    "Comme indiqué précédemment, il peut être long d'entraîner un modèle (plusieurs heures). Et il vaut donc mieux utiliser les lignes qui suivent avec précaution.\n",
    "Dans un premier temps, on va évaluer les performances sans rotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/home/tesbed/datasets/miniimagenet/\"\n",
    "\n",
    "def load_datasets(root):\n",
    "    datasets = {}\n",
    "    class_index = 0\n",
    "    for subset in [\"train\", \"validation\", \"test\"]:\n",
    "        f = open(root + \"mini-imagenet-cache-\" + subset + \".pkl\", \"rb\")\n",
    "        dataset = pickle.load(f)\n",
    "        data = dataset['image_data']\n",
    "        target = torch.zeros(data.shape[0], dtype=int)\n",
    "        for cl in dataset['class_dict'].keys():\n",
    "            for elt in dataset['class_dict'][cl]:\n",
    "                target[elt] = class_index\n",
    "            class_index += 1\n",
    "        datasets[subset] = [data, target]\n",
    "    return datasets\n",
    "\n",
    "class MiniImageNet(VisionDataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root : str,\n",
    "            subset = \"train\",\n",
    "            transform: Optional[Callable] = None,\n",
    "            target_transform: Optional[Callable] = None\n",
    "    ) -> None:\n",
    "\n",
    "        super(MiniImageNet, self).__init__(root, transform=transform, target_transform=target_transform)\n",
    "\n",
    "        self.data: Any = []\n",
    "        self.targets = []\n",
    "\n",
    "        datasets = load_datasets(root)\n",
    "        \n",
    "        self.data = datasets[subset][0]\n",
    "        self.targets = datasets[subset][1]\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "batch_size = 64\n",
    "\n",
    "from PIL import ImageEnhance\n",
    "\n",
    "transformtypedict=dict(Brightness=ImageEnhance.Brightness, Contrast=ImageEnhance.Contrast, Sharpness=ImageEnhance.Sharpness, Color=ImageEnhance.Color)\n",
    "\n",
    "class ImageJitter(object):\n",
    "    def __init__(self, transformdict):\n",
    "        self.transforms = [(transformtypedict[k], transformdict[k]) for k in transformdict]\n",
    "\n",
    "\n",
    "    def __call__(self, img):\n",
    "        out = img\n",
    "        randtensor = torch.rand(len(self.transforms))\n",
    "\n",
    "        for i, (transformer, alpha) in enumerate(self.transforms):\n",
    "            r = alpha*(randtensor[i]*2.0 -1.0) + 1\n",
    "            out = transformer(out).enhance(r).convert('RGB')\n",
    "\n",
    "        return out\n",
    "\n",
    "train_transforms = [   \n",
    "    transforms.RandomResizedCrop(80),\n",
    "    ImageJitter(dict(Brightness=0.4, Contrast=0.4, Color=0.4)),\n",
    "    transforms.RandomHorizontalFlip()\n",
    "    ] # used for standard data augmentation during training\n",
    "\n",
    "test_transforms = [\n",
    "    transforms.Resize([int(80*1.15), int(80*1.15)]),\n",
    "    transforms.CenterCrop(80)\n",
    "]\n",
    "\n",
    "standard_transforms = [\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406) ,(0.229, 0.224, 0.225))\n",
    "    ] # used for all data\n",
    "\n",
    "transform_train = transforms.Compose(train_transforms + standard_transforms)\n",
    "transform_all = transforms.Compose(test_transforms + standard_transforms)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    MiniImageNet(root, subset=\"train\", transform=transform_train),\n",
    "    batch_size=batch_size, shuffle=True, num_workers = 4)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    MiniImageNet(root, subset=\"validation\", transform=transform_all),\n",
    "    batch_size=batch_size, shuffle=False, num_workers = 4)\n",
    "\n",
    "novel_loader = torch.utils.data.DataLoader(\n",
    "    MiniImageNet(root, subset=\"test\", transform=transform_all),\n",
    "    batch_size=batch_size, shuffle=False, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_maps = 16\n",
    "epochs = 100\n",
    "\n",
    "for type_features in [\"post\", \"all\", \"pre\"]:\n",
    "    print(type_features)\n",
    "    model = WideResNet(16).to(device)\n",
    "    for lr, valid in [(0.1, False), (0.01, False), (0.001, False), (0.0001, True)]:\n",
    "        train_model(model, epochs, lr, validate, val_loader, novel_loader, type_features = type_features, validate_each_epoch = valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
